name: Refresh Reddit Video Data

on:
  # Schedule to run every hour
  schedule:
    - cron: '0 * * * *' # Runs at minute 0 of every hour

  # Allows running this workflow manually from the Actions tab
  workflow_dispatch:

  # Trigger on every push to the 'main' branch
  push:
    branches:
      - main # Change to 'master' if that's your default branch name

jobs:
  refresh-data:
    runs-on: ubuntu-latest # Use a standard Linux runner

    steps:
    - name: Check out repository code
      uses: actions/checkout@v4 # Use latest checkout action

    - name: Set up Python
      uses: actions/setup-python@v5 # Use latest setup-python action
      with:
        python-version: '3.10' # Or your preferred Python 3 version

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install praw

    - name: Run Python script to fetch data
      # Inject secrets as environment variables for the script
      env:
        REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
        REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
        REDDIT_USERNAME: ${{ secrets.REDDIT_USERNAME }}
        REDDIT_PASSWORD: ${{ secrets.REDDIT_PASSWORD }}
      run: python get_videos.py

    - name: Commit and push if JSON files changed
      run: |
        git config --global user.name 'github-actions[bot]' # Use bot name for commit
        git config --global user.email 'github-actions[bot]@users.noreply.github.com'
        # Add all JSON files that might have changed
        git add videos_*.json
        # Check if there are changes staged
        # Use 'git diff --staged --quiet ||' to commit only if changes exist
        # The '|| true' ensures the step doesn't fail if there are no changes to commit
        if ! git diff --staged --quiet; then
          git commit -m "Automated update: Refresh Reddit video data"
          git push
          echo "Changes committed and pushed."
        else
          echo "No changes to commit."
        fi